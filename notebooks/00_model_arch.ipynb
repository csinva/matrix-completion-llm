{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import transformers\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from mcllm.model.llm import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_low_rank_matrix(m, n, rank):\n",
    "    A = np.random.randn(m, rank) @ np.random.randn(rank, n)\n",
    "    return A\n",
    "\n",
    "\n",
    "mat = create_low_rank_matrix(10, 10, rank=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([1, 100]) torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# single prediction\n",
    "\n",
    "seq_len = 100\n",
    "llm = NanoBERT(vocab_size=100, max_seq_len=seq_len)\n",
    "batch_size = 1\n",
    "x = torch.LongTensor(np.zeros((batch_size, seq_len)))\n",
    "out = llm(x)\n",
    "print('shapes', x.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss 0.002657452132552862\n",
      "Epoch: 2\n",
      "Train loss 0.007548022549599409\n",
      "Epoch: 3\n",
      "Train loss 0.0009820930426940322\n",
      "Epoch: 4\n",
      "Train loss 0.00149148132186383\n",
      "Epoch: 5\n",
      "Train loss 0.004250728990882635\n",
      "Epoch: 6\n",
      "Train loss 0.0023586226161569357\n",
      "Epoch: 7\n",
      "Train loss 0.0003296678769402206\n",
      "Epoch: 8\n",
      "Train loss 0.0003778900427278131\n",
      "Epoch: 9\n",
      "Train loss 0.0017221131129190326\n",
      "Epoch: 10\n",
      "Train loss 0.0020630392245948315\n"
     ]
    }
   ],
   "source": [
    "# train on 1 example\n",
    "device = 'cuda'\n",
    "num_epochs = 10\n",
    "lr = 1e-2\n",
    "llm = llm.to(device)\n",
    "optimizer = torch.optim.Adam(llm.parameters(), lr=lr)\n",
    "llm.train()\n",
    "for i in range(num_epochs):\n",
    "    print(f'Epoch: {i + 1}')\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "\n",
    "    llm.train()\n",
    "    # for step, batch in enumerate(tqdm(dataloader.get_split('train'), total=dataloader.steps('train'))):\n",
    "    x = torch.LongTensor(np.zeros((batch_size, seq_len))).to(device)\n",
    "    pred = llm(x)\n",
    "    loss = F.mse_loss(x.float(), pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    # bert.eval()\n",
    "    # for step, batch in enumerate(tqdm(dataloader.get_split('val'), total=dataloader.steps('val'))):\n",
    "    #     logits = bert(batch['input_ids'].to(device))\n",
    "\n",
    "    #     probs = F.softmax(logits[:, 0, :], dim=-1).cpu()\n",
    "    #     pred = torch.argmax(probs, dim=-1)  # (B)\n",
    "    #     val_preds += pred.detach().tolist()\n",
    "    #     val_labels += [l.item() for l in batch['label_ids']]\n",
    "\n",
    "    #     loss = F.cross_entropy(logits[:, 0, :].cpu(), batch['label_ids'])\n",
    "\n",
    "    #     val_loss += loss.item()\n",
    "\n",
    "    # print()\n",
    "    print(f'Train loss {train_loss}')\n",
    "    #     f'Train loss: {train_loss / dataloader.steps(\"train\")} | Val loss: {val_loss / dataloader.steps(\"val\")}')\n",
    "    # print(\n",
    "    #     f'Train acc: {accuracy_score(train_labels, train_preds)} | Val acc: {accuracy_score(val_labels, val_preds)}')\n",
    "    # print(\n",
    "    #     f'Train f1: {f1_score(train_labels, train_preds)} | Val f1: {f1_score(val_labels, val_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
